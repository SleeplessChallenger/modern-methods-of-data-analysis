{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894c84a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "x = pd.read_excel('')\n",
    "x['Churn'] = x['Churn'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "x['MaritalStatus'] = pd.get_dummies(x['MaritalStatus'])['Yes']\n",
    "\n",
    "x.shape\n",
    "# Categorizing two features: 16.\n",
    "\n",
    "# 1 feature\n",
    "\n",
    "plt.hist(x['MonthlyMinutes'], bins=int(np.round(np.sqrt(x.shape[0]))))\n",
    "plt.title(\"Histogram of first feature\")\n",
    "plt.show()\n",
    "# boundaries for four categories of first feature : [0, 500, 900,4000]\n",
    "plt.hist(x['OutboundCalls'], bins=int(np.round(np.sqrt(x.shape[0]))))\n",
    "plt.title(\"Histogram of second feature\")\n",
    "plt.show()\n",
    "# boundaries for four categories of second feature : [0, 15, 30, 55,280]\n",
    "parts_names = ['Professional', \"Retired\", \"Self\", \"Student\"]\n",
    "# take that values in nominal feature Occupation,\n",
    "# as that values are approximately 80% jf all data\n",
    "\n",
    "# create 2 nominal features from MonthlyMinutes\n",
    "# and OutboundCalls\n",
    "\n",
    "x['new_nominal_f1'] = 0\n",
    "for i in range(x.shape[0]):\n",
    "    x['new_nominal_f2'] = 0\n",
    "\n",
    "    if 0 <= x.iloc[i, 1] <= 500:\n",
    "        x.iloc[i, -1] = 1\n",
    "    elif 500 < x.iloc[i, 1] <= 900:\n",
    "        x.iloc[i, -1] = 2\n",
    "    else:\n",
    "        x.iloc[i, -1] = 3\n",
    "\n",
    "x['new_nominal_f2'] = 0\n",
    "for i in range(x.shape[0]):\n",
    "    if 0 <= x.iloc[i, 3] <= 15:\n",
    "        x.iloc[i, -1] = 1\n",
    "    elif 15 < x.iloc[i, 3] <= 30:\n",
    "        x.iloc[i, -1] = 2\n",
    "    elif 30 < x.iloc[i, 3] <= 55:\n",
    "        x.iloc[i, -1] = 3\n",
    "    else:\n",
    "        x.iloc[i, -1] = 4\n",
    "\n",
    "x_ = np.array(x.copy())\n",
    "x_ = x_[np.isin(x_[:, -3], parts_names)]\n",
    "\n",
    "\n",
    "def contingency_table(subset_1, subset_2):\n",
    "    \"\"\"\n",
    "     An slower yet more intuitive way to create contingency table.\n",
    "     returns contingency tables of two subsets,\n",
    "     so that the last column and last row represent the\n",
    "     marginal frequencies of Tk and Gl.\n",
    "      \"\"\"\n",
    "    cat_1, cat_1_idx = np.unique(subset_1, return_inverse=True)\n",
    "    cat_2, cat_2_idx = np.unique(subset_2, return_inverse=True)\n",
    "    n_cat_1 = cat_1.shape[0]\n",
    "    n_cat_2 = cat_2.shape[0]\n",
    "    contingency = np.zeros([n_cat_1 + 1, n_cat_2 + 1], dtype=np.int)\n",
    "\n",
    "    for row in range(n_cat_1):\n",
    "        for col in range(n_cat_2):\n",
    "            n_rc = len(set(np.where(cat_1_idx == row)[0].tolist()).intersection(\n",
    "                set(np.where(cat_2_idx == col)[0].tolist())))\n",
    "            contingency[row, col] = n_rc\n",
    "\n",
    "        contingency[row, -1] = np.sum(contingency[row, :])\n",
    "\n",
    "    contingency[-1, :] = np.sum(contingency, axis=0)\n",
    "    relative_frequencies = np.divide(contingency, contingency[-1, -1])\n",
    "    return contingency, relative_frequencies\n",
    "\n",
    "\n",
    "# create the contingency tables\n",
    "contingency_T_G, rel_freq_T_G = contingency_table(x_[:, -2], x_[:, -1])\n",
    "print(\"contingency P(T|G):\", \"\\n\", )\n",
    "print(contingency_T_G)\n",
    "print(\" \")\n",
    "print(\"prob P(T|G):\", \"\\n\", )\n",
    "print(rel_freq_T_G)\n",
    "\n",
    "contingency_T_H, rel_freq_T_H = contingency_table(x_[:, -2], x_[:, -3])  # TgivenH\n",
    "print(\"contingency P(T|H):\", \"\\n\", )\n",
    "print(contingency_T_H)\n",
    "print(\" \")\n",
    "print(\"prob P(T|H):\", \"\\n\", )\n",
    "\n",
    "marg_freq_T = contingency_T_G[:-1, -1:]\n",
    "marg_freq_G = contingency_T_G[-1, :-1]\n",
    "marg_freq_H = contingency_T_H[-1, :-1]\n",
    "\n",
    "conditional_T_G = np.divide(contingency_T_G[:-1, :-1], marg_freq_G)\n",
    "print(\"Conditional T given G:\", \"\\n \\n\", conditional_T_G)\n",
    "\n",
    "conditional_T_H = np.divide(contingency_T_H[:-1, :-1], marg_freq_H)\n",
    "print(\"Conditional T given H:\", \"\\n \\n\", conditional_T_H)\n",
    "\n",
    "quetelet_T_G = np.subtract(np.divide(conditional_T_G, marg_freq_T / x_.shape[0]), 1)\n",
    "quetelet_T_G\n",
    "\n",
    "quetelet_T_H = np.subtract(np.divide(conditional_T_H, marg_freq_T / x_.shape[0]), 1)\n",
    "quetelet_T_H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78413559",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_chi2(rel_freq, indep_prob):\n",
    "    \"As per slides page 50\"\n",
    "    d = np.subtract(rel_freq[:-1, :-1], indep_prob)\n",
    "    dd = np.power(d, 2)\n",
    "    chi = np.divide(dd, indep_T_n_G)\n",
    "    chi2 = np.sum(chi)\n",
    "    return chi2\n",
    "\n",
    "\n",
    "# Observed relative contingency table and the table of Quetelet indices\n",
    "ave_quet_idx_T_G = np.sum(rel_freq_T_G[:-1, :-1].reshape(1, -1) * quetelet_T_G.reshape(1, -1))\n",
    "print(\"average Quetelet Index T given G:\", ave_quet_idx_T_G)\n",
    "\n",
    "# Independent probabilities:\n",
    "indep_T_n_G = marg_freq_T / x_.shape[0] @ marg_freq_G.reshape(1, -1) / x_.shape[0]\n",
    "indep_T_n_H = marg_freq_T / x_.shape[0] @ marg_freq_H.reshape(1, -1) / x_.shape[0]\n",
    "chi2_T_G = compute_chi2(rel_freq_T_G, indep_T_n_G)\n",
    "print(\"Chi2:\", ave_quet_idx_T_G)\n",
    "\n",
    "print('at N > ' + str(\n",
    "    12.592 // 0.55425 + 1) + ' the hypothesis of statistical independence should be rejected at 95% confidence level.')\n",
    "print('at N > ' + str(\n",
    "    22.458 // 0.55425 + 1) + ' the hypothesis of statistical independence should be rejected at 99% confidence level.')\n",
    "print('we have N = 432 => not ind')\n",
    "ave_quet_idx_T_H = np.sum(rel_freq_T_H[:-1, :-1].reshape(1, -1) * quetelet_T_H.reshape(1, -1))\n",
    "print(\"average Quetelet Index T given H:\", ave_quet_idx_T_H)\n",
    "\n",
    "chi2_T_H = compute_chi2(rel_freq_T_H, indep_T_n_H)\n",
    "print(\"Chi2:\", ave_quet_idx_T_H)\n",
    "\n",
    "print('at N > ' + str(\n",
    "    12.592 // 0.0164 + 1) + ' the hypothesis of statistical independence should be rejected at 95% confidence level.')\n",
    "print('at N > ' + str(\n",
    "    22.458 // 0.0164 + 1) + ' the hypothesis of statistical independence should be rejected at 99% confidence level.')\n",
    "print('we have N = 432 => ind')\n",
    "\n",
    "heat_map_quet_T_G = (rel_freq_T_G[:-1, :-1].reshape(1, -1) * quetelet_T_G.reshape(1, -1)).reshape(3, 4)\n",
    "heat_map_quet_T_G\n",
    "\n",
    "plt.imshow(heat_map_quet_T_G, cmap='hot',\n",
    "           interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "heat_map_quet_T_H = (rel_freq_T_H[:-1, :-1].reshape(1, -1) * quetelet_T_H.reshape(1, -1)).reshape(3, 4)\n",
    "heat_map_quet_T_H\n",
    "\n",
    "plt.imshow(heat_map_quet_T_H, cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
